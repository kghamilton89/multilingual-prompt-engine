{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "import markdown\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import subprocess\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face.\n"
     ]
    }
   ],
   "source": [
    "# Log in to Hugging Face\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "HfFolder.save_token(hf_token)\n",
    "\n",
    "\n",
    "result = subprocess.run([\"huggingface-cli\", \"login\", \"--token\", hf_token], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"Successfully logged in to Hugging Face.\")\n",
    "else:\n",
    "    print(\"Failed to log in to Hugging Face.\")\n",
    "    print(result.stderr.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: DIBT/MPEP_DUTCH\n",
      "Als een AI-enthousiasteling, houd je ervan om programma's te maken die de menselijke taal begrijpen. Je nieuwste project is een programma dat woorden kan herkennen en vervangen door hun antoniemen in een stuk tekst.\n",
      "Om de effectiviteit van je programma aan te tonen, besluit je het te testen op een nieuwsartikel over een recent politiek evenement. Om het uitdagender te maken, wil je ook dat je programma onderscheid maakt tussen homoniemen, en daarnaast contextuele aanwijzingen gebruikt woorden correct te vervangen.\n",
      "Hier is een stapsgewijze uitleg van hoe je programma werkt:\n",
      "1. Het programma leest de inputtekst en identificeert alle woorden die antoniemen hebben.\n",
      "2. Voor elk van deze woorden identificeert het programma de context waarin het verschijnt om het juiste antoniem te bepalen.\n",
      "3. Het programma vervangt vervolgens het originele woord door zijn antoniem in de tekst.\n",
      "4. Als het originele woord meerdere betekenissen heeft, gebruikt het programma de context om te bepalen welke betekenis bedoeld is en vervangt het door het passende antoniem.\n",
      "5. Uiteindelijk geeft het programma de aangepaste tekst uit met de vervangen woorden.\n",
      "Kun je je vaardigheden in natuurlijke taalverwerking op de proef stellen en proberen de antoniemen te identificeren die in de gewijzigde tekst worden gebruikt?\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_SPANISH\n",
      "Dado el texto: Una innovadora experimentada y entusiasta... que quieres en tu equipo.\n",
      "Margaret Hines es la fundadora y Consultora Principal de Inspire Marketing, LLC, que invierte en negocios locales, sirviendo a la comunidad con consultoría de negocios y marketing. Ella tiene un título universitario de la Universidad de Washington en St. Louis, MO, y un MBA de la Universidad de Wisconsin-Milwaukee.\n",
      "Margaret ofrece consultoría en marketing, ventas de negocios, transformaciones de negocios y franquicias. También es inversora en negocios locales.\n",
      "Antes de fundar Inspire Marketing en 2003, Margaret adquirió su habilidad para los negocios, experiencia en ventas y marketing mientras trabajaba en respetadas empresas de Fortune 1000.\n",
      "Resume la formación y experiencia de Margaret Hines, la fundadora de Inspire Marketing.\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 23.5k/23.5k [00:00<00:00, 12.4MB/s]\n",
      "Downloading data: 100%|██████████| 26.6k/26.6k [00:00<00:00, 42.5kB/s]\n",
      "Generating train split: 100%|██████████| 26/26 [00:00<00:00, 1210.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: DIBT/MPEP_MALAGASY\n",
      "Mila CV aho ho an'ity asa ity\n",
      "Junior PHP injeniera (f / m / d)\n",
      "Momba ny asa\n",
      "Anstellungsdetails\n",
      "\n",
      "Fifanekena maharitra, fotoana feno na tapak'andro, Cologne / Düsseldorf / Darmstadt / Remote (any Alemaina)\n",
      "\n",
      "Info\n",
      "\n",
      "Iza moa isika\n",
      "\n",
      "Miasa Kaufland.de izahay: mpivarotra an'arivony sy vokatra an-tapitrisany no mahatonga antsika ho iray amin'ireo tsena an-tserasera mitombo haingana indrindra. Ny asanay dia miavaka amin'ny kolontsain'ny orinasa mavitrika, miaraka amin'ny toe-tsaina manomboka sy ny herin'ny vondrona orinasa lehibe. Manambatra ny fahalalana sy ny traikefa an-taonany maro amin'ny e-varotra miaraka amin'ny ambaratongam-pahefana sy ekipa tena manosika izahay. Na avy amin'ny intern: Raisinay ho zava-dehibe ny hevitra rehetra, satria te-hiara-hiasa amin'ny famolavolana ny hoavin'ny e-varotra izahay!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_GERMAN\n",
      "Kannst du zwei Beispiele für Metaphern im Excel-Tabellenformat liefern?\n",
      "\n",
      "Hier ist eine Excel-Tabelle mit zwei Beispielen für Metaphern:\n",
      "\n",
      "| Metapher        | Bedeutung           |\n",
      "\n",
      "| ------------- |:-------------:|\n",
      "\n",
      "| Das Leben ist eine Reise | Das Leben kann mit einer Reise mit Höhen und Tiefen verglichen werden |\n",
      "\n",
      "| Liebe ist wie eine Rose  | Liebe kann mit einer zarten und schönen Rose verglichen werden |\n",
      "\n",
      "Kannst du zwei weitere Beispiele für Metaphern in einem MATLAB-Codeformat liefern?\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_SWAHILI\n",
      "Ungefafanuaje manyoya ya mbwa wa mlima wa Uswisi?\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_FILIPINO\n",
      "ano ang papel na ginagampanan ng pass transistor at op amp sa isang regulator\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_ARABIC\n",
      "إذا كانت الوصفة تتطلب كوبين ونصف من السكر وتريد تحضير نصف هذه الكمية، فاحسب كمية السكر المطلوبة بالضبط.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_CZECH\n",
      "Jaký je vliv změny klimatu na polární ledové čepice a jak ovlivňuje globální hladinu moří?\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_HUNGARIAN\n",
      "Mint mesterséges intelligencia rajongó, szeretsz olyan programokat készíteni, amelyek képesek megérteni az emberi nyelvet. Legújabb projekted egy olyan program fejlesztése, amely képes felismerni és kicserélni a szavakat azok ellentéteire egy adott szövegben.\n",
      "Annak érdekében, hogy bemutasd a program hatékonyságát, úgy döntesz, hogy teszteled azt egy újságcikken, amely egy nemrégiben történt politikai eseményről szól. Azonban, hogy még nagyobb kihívást jelentsen, azt is szeretnéd, ha a program megkülönböztetné a homonimákat és a kontextus alapján helyesen cserélné ki azokat.\n",
      "Íme, egy lépésről-lépésre leírás a program működéséről:\n",
      "1. A program beolvassa a bemeneti szöveget és azonosít minden olyan szót, amelynek van ellentéte.\n",
      "2. Minden ilyen szó esetén a program azonosítja a kontextust, amelyben megjelennek, hogy meghatározza a helyes ellentétes szót, amit használni kell.\n",
      "3. A program ezután kicseréli az eredeti szót annak ellentetjére a szövegben.\n",
      "4. Ha az eredeti szónak több jelentése is van, a program a kontextust használja annak meghatározására, hogy melyik jelentés értendő, és kicseréli a megfelelő ellentétes szóra.\n",
      "5. Végül a program visszaadja a módosított szöveget a kicserélt szavakkal.\n",
      "Próbára tennéd a természetes nyelvfeldolgozási képességeidet, hogy azonosítsd a módosított szövegben használt ellentéteket?\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_RUSSIAN\n",
      "Учитывая текст: Опытный и энтузиастичный новатор... вы хотите в своей команде. Маргарет Хайнс является основателем и главным консультантом Inspire Marketing, LLC, инвестирующей в местные предприятия, обслуживающей сообщество бизнес-брокером и маркетинговым консультированием. Она имеет степень бакалавра в Вашингтонском университете в Сент-Луисе, штат Москва, и MBA из Университета Висконсинка-Милваки. Маргарет предлагает консультации в области маркетинга, продаж бизнеса и поворотов и франчайзинга.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: DIBT/MPEP_GREEK\n",
      "Βάσει του κειμένου: Μία έμπειρη και ενθουσιώδης καινοτόμος... που θέλετε στην ομάδα σας.\n",
      "Η Margaret Hines είναι η ιδρύτρια και η κύρια σύμβουλος της Inspire Marketing, LLC, έχοντας επενδύσει σε τοπικές επιχειρήσεις, εξυπηρετώντας την κοινότητα μέσω επιχειρηματικής μεσιτείας και συμβουλών μάρκετινγκ. Έχει πτυχίο από το Πανεπιστήμιο της Ουάσιγκτον στο St. Louis, MO, και MBA από το Πανεπιστήμιο του Wisconsin-Milwaukee.\n",
      "Η Margaret προσφέρει συμβουλές σε θέματα μάρκετινγκ, επιχειρηματικών πωλήσεων και ανακατασκευών και franchising. Είναι επίσης επενδύτρια σε τοπικές επιχειρήσεις.\n",
      "Πριν από την ίδρυση της Inspire Marketing το 2003, η Margaret απέκτησε την επιχειρηματική της οξυδέρκεια, και την τεχνογνωσία της στις πωλήσεις και το μάρκετινγκ όσο εργαζόταν σε αναγνωρισμένες εταιρείες του Fortune 1000.\n",
      "Συνόψισε το ιστορικό και την τεχνογνωσία της Margaret Hines, της ιδρύτριας του Inspire Marketing.\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect and print MPEP datasets\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "def search_datasets_by_label(label):\n",
    "    datasets = api.list_datasets(search=label)\n",
    "    return datasets\n",
    "\n",
    "mpep_datasets = search_datasets_by_label('MPEP')\n",
    "\n",
    "# Extract and print the first entry's value parameter from the target JSON object for each dataset\n",
    "for dataset in mpep_datasets:\n",
    "    ds = load_dataset(dataset.id)\n",
    "    target_entries = ds['train']['target'][:1]\n",
    "    print(f\"Dataset: {dataset.id}\")\n",
    "    if target_entries:\n",
    "        first_target = target_entries[0]\n",
    "        if isinstance(first_target, list) and first_target:\n",
    "            value = first_target[0].get('value', 'No value found')\n",
    "            print(value)\n",
    "        elif isinstance(first_target, dict):\n",
    "            value = first_target.get('value', 'No value found')\n",
    "            print(value)\n",
    "        else:\n",
    "            print(\"No target value found\")\n",
    "    else:\n",
    "        print(\"No target entries found\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def query_hf_inference(model, prompt, token):\n",
    "    api_url = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json={\"inputs\": prompt}, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                result = response.json()\n",
    "                if isinstance(result, list) and len(result) > 0:\n",
    "                    return result[0].get('generated_text', 'No generated text found')\n",
    "                else:\n",
    "                    return \"Unexpected response format\"\n",
    "            except ValueError:\n",
    "                return \"Invalid JSON response\"\n",
    "        else:\n",
    "            return f\"Error {response.status_code}: {response.text}\"\n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"Request timed out\"\n",
    "\n",
    "\n",
    "# List of target models\n",
    "models = [\n",
    "    \"google/gemma-2-27b-it\",\n",
    "    \"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "    \"Qwen/Qwen2-72B-Instruct\",\n",
    "    \"mistralai/Mixtral-8x22B-Instruct-v0.1\",\n",
    "]\n",
    "\n",
    "# Number of prompts to process\n",
    "num_prompts = 5\n",
    "\n",
    "def search_datasets_by_label(label):\n",
    "    # Search datasets with the specified label\n",
    "    datasets = api.list_datasets(search=label)\n",
    "    return datasets\n",
    "\n",
    "# Search for datasets with the \"MPEP\" label\n",
    "mpep_datasets = search_datasets_by_label('MPEP')\n",
    "\n",
    "# Directory to save responses\n",
    "os.makedirs('./responses', exist_ok=True)\n",
    "\n",
    "# Process each dataset\n",
    "for dataset in mpep_datasets:\n",
    "    # Load the dataset\n",
    "    ds = load_dataset(dataset.id)\n",
    "    # Extract the first 'num_prompts' entries from the target JSON object\n",
    "    target_entries = ds['train']['target'][:num_prompts]\n",
    "    \n",
    "    # Get the language from the dataset id (assuming the format is consistent)\n",
    "    language = dataset.id.split('_')[-1].lower()\n",
    "    \n",
    "    # Open a file to write the responses\n",
    "    with open(f'./responses/{language}.md', 'w') as file:\n",
    "        # Capture responses for each model\n",
    "        for model in models:\n",
    "            file.write(f\"# Model: {model}\\n\\n\")\n",
    "            for target_entry in target_entries:\n",
    "                if isinstance(target_entry, list) and target_entry:\n",
    "                    prompt = target_entry[0].get('value', 'No value found')\n",
    "                elif isinstance(target_entry, dict):\n",
    "                    prompt = target_entry.get('value', 'No value found')\n",
    "                else:\n",
    "                    prompt = \"No prompt found\"\n",
    "                \n",
    "                response_text = query_hf_inference(model, prompt, os.getenv('HF_TOKEN'))\n",
    "                file.write(f\"## Prompt:\\n{prompt}\\n\\n\")\n",
    "                file.write(f\"## Response:\\n{response_text}\\n\\n\")\n",
    "                file.write(\"\\n\" + \"-\"*40 + \"\\n\\n\")\n",
    "\n",
    "print(\"Script completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
